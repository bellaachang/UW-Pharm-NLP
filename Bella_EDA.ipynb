{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_EcgXJRvg-JU"
      },
      "outputs": [],
      "source": [
        "#%pip install pyldavis\n",
        "#%pip install spacy\n",
        "#!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmKAUrHs9v8I",
        "outputId": "f074dbd8-573e-4041-b930-7caea6cb872a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\jergx\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\jergx\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# import pyLDAvis\n",
        "# import pyLDAvis.gensim\n",
        "\n",
        "import spacy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr0sDipDo9Uj"
      },
      "source": [
        "## DATA LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "B6Le_F1e97UV",
        "outputId": "8b40ce28-b53c-4c28-cd17-33cec94ea883"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subj #</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>Win 1_2</th>\n",
              "      <th>Win 3_4</th>\n",
              "      <th>Win 5_6</th>\n",
              "      <th>Win 7_8</th>\n",
              "      <th>Win 9_10</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "      <th>Spr 1_2</th>\n",
              "      <th>Spr 3_4</th>\n",
              "      <th>Spr 5_6</th>\n",
              "      <th>Spr 7-8</th>\n",
              "      <th>Spr 9-10</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "      <th>CPD_Q1</th>\n",
              "      <th>CPD_Q2</th>\n",
              "      <th>CPD_Q3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Took the time to do some meal prep last night ...</td>\n",
              "      <td>I spent time before work to do an easy 20-minu...</td>\n",
              "      <td>Took a nap before work since my team this week...</td>\n",
              "      <td>Called a friend who happened to be on her lunc...</td>\n",
              "      <td>Took a walk outside to take in some of the rar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Had a very busy weekend with my sister visitin...</td>\n",
              "      <td>Spent some time on the phone catching up with ...</td>\n",
              "      <td>Gave myself time to lie down on the couch and ...</td>\n",
              "      <td>Took a nap after class and ended up sleeping t...</td>\n",
              "      <td>Set aside and spent some time at night after s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The class time devoted to health and wellness ...</td>\n",
              "      <td>During my gap years I gained a lot of insight ...</td>\n",
              "      <td>I believe self-care to be really important in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1. Select one of the activities that resonates...</td>\n",
              "      <td>One of the activities that I chose from the Ch...</td>\n",
              "      <td>One of the activities that I chose for self-ca...</td>\n",
              "      <td>For my self care, I went on a walk and listene...</td>\n",
              "      <td>One of the activities that I chose for health/...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I decided to spend my self care time by going ...</td>\n",
              "      <td>For my self care, I decided to find new music ...</td>\n",
              "      <td>I went on a run!</td>\n",
              "      <td>I watched TV with my dad!</td>\n",
              "      <td>I painted my nails! This is something I really...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The class time devoted to health and wellness ...</td>\n",
              "      <td>The way I decided which self-care to choose wa...</td>\n",
              "      <td>The time spent on my choice of self-care allow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Today, I cooked myself lunch and it was delici...</td>\n",
              "      <td>I took a walk around campus with my roommate t...</td>\n",
              "      <td>I listened to some of my favorite artists whil...</td>\n",
              "      <td>Today, I spent my break eating good food and w...</td>\n",
              "      <td>Today, I spent some of my time watching a show...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I took the time to finish building my baby Yod...</td>\n",
              "      <td>I took the time to reach out and talk to one o...</td>\n",
              "      <td>This week I spent at least 20 minutes reading ...</td>\n",
              "      <td>This week I spent about an hour getting dinner...</td>\n",
              "      <td>This weekend, I went shopping with my friend a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The class time has reminded me on the importan...</td>\n",
              "      <td>To decide on what to do it would mostly depend...</td>\n",
              "      <td>The time spent on my choice of self care affec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I worked on my Paint by Diamond piece.</td>\n",
              "      <td>I worked on more of the Paint by Diamonds.</td>\n",
              "      <td>I worked on my Paint by Diamond while listenin...</td>\n",
              "      <td>I worked on my Paint by Diamond while listenin...</td>\n",
              "      <td>I grabbed lunch with a friend.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I started a new Asian drama (tv show) called T...</td>\n",
              "      <td>I took a walk around my neighborhood while lis...</td>\n",
              "      <td>I took a walk to my neighborhood park , sat on...</td>\n",
              "      <td>I went to go visit my high school teachers.</td>\n",
              "      <td>I went out and had lunch with my brother.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The class time that was devoted to health and ...</td>\n",
              "      <td>For me, it depends on the weather à if it was ...</td>\n",
              "      <td>It made me more relaxed and less stressed abou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I took a 20 minutes walk from the train statio...</td>\n",
              "      <td>I met up with my friends for coffee and it was...</td>\n",
              "      <td>I soaked in the bathtub for an hour with relax...</td>\n",
              "      <td>I walked around the neighborhood for thirty mi...</td>\n",
              "      <td>I tried to using  peloton in our apartment bui...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yesterday was my birthday and my boyfriend pla...</td>\n",
              "      <td>I am increasing my cardio work out in the apar...</td>\n",
              "      <td>I went to watch movie at ipic theatre in redmo...</td>\n",
              "      <td>I took a 30 minutes walk in my new neighborhoo...</td>\n",
              "      <td>It was a nice day today and my friend and I to...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I have learnt to listen to people without inte...</td>\n",
              "      <td>This is because I wanted to connect with mysel...</td>\n",
              "      <td>This has been a lifeline because I always felt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Subj #  Unnamed: 1                                            Win 1_2  \\\n",
              "0       1         NaN  Took the time to do some meal prep last night ...   \n",
              "1       2         NaN  1. Select one of the activities that resonates...   \n",
              "2       3         NaN  Today, I cooked myself lunch and it was delici...   \n",
              "3       4         NaN             I worked on my Paint by Diamond piece.   \n",
              "4       5         NaN  I took a 20 minutes walk from the train statio...   \n",
              "\n",
              "                                             Win 3_4  \\\n",
              "0  I spent time before work to do an easy 20-minu...   \n",
              "1  One of the activities that I chose from the Ch...   \n",
              "2  I took a walk around campus with my roommate t...   \n",
              "3         I worked on more of the Paint by Diamonds.   \n",
              "4  I met up with my friends for coffee and it was...   \n",
              "\n",
              "                                             Win 5_6  \\\n",
              "0  Took a nap before work since my team this week...   \n",
              "1  One of the activities that I chose for self-ca...   \n",
              "2  I listened to some of my favorite artists whil...   \n",
              "3  I worked on my Paint by Diamond while listenin...   \n",
              "4  I soaked in the bathtub for an hour with relax...   \n",
              "\n",
              "                                             Win 7_8  \\\n",
              "0  Called a friend who happened to be on her lunc...   \n",
              "1  For my self care, I went on a walk and listene...   \n",
              "2  Today, I spent my break eating good food and w...   \n",
              "3  I worked on my Paint by Diamond while listenin...   \n",
              "4  I walked around the neighborhood for thirty mi...   \n",
              "\n",
              "                                            Win 9_10  Unnamed: 7  \\\n",
              "0  Took a walk outside to take in some of the rar...         NaN   \n",
              "1  One of the activities that I chose for health/...         NaN   \n",
              "2  Today, I spent some of my time watching a show...         NaN   \n",
              "3                     I grabbed lunch with a friend.         NaN   \n",
              "4  I tried to using  peloton in our apartment bui...         NaN   \n",
              "\n",
              "                                             Spr 1_2  \\\n",
              "0  Had a very busy weekend with my sister visitin...   \n",
              "1  I decided to spend my self care time by going ...   \n",
              "2  I took the time to finish building my baby Yod...   \n",
              "3  I started a new Asian drama (tv show) called T...   \n",
              "4  Yesterday was my birthday and my boyfriend pla...   \n",
              "\n",
              "                                             Spr 3_4  \\\n",
              "0  Spent some time on the phone catching up with ...   \n",
              "1  For my self care, I decided to find new music ...   \n",
              "2  I took the time to reach out and talk to one o...   \n",
              "3  I took a walk around my neighborhood while lis...   \n",
              "4  I am increasing my cardio work out in the apar...   \n",
              "\n",
              "                                             Spr 5_6  \\\n",
              "0  Gave myself time to lie down on the couch and ...   \n",
              "1                                   I went on a run!   \n",
              "2  This week I spent at least 20 minutes reading ...   \n",
              "3  I took a walk to my neighborhood park , sat on...   \n",
              "4  I went to watch movie at ipic theatre in redmo...   \n",
              "\n",
              "                                             Spr 7-8  \\\n",
              "0  Took a nap after class and ended up sleeping t...   \n",
              "1                          I watched TV with my dad!   \n",
              "2  This week I spent about an hour getting dinner...   \n",
              "3        I went to go visit my high school teachers.   \n",
              "4  I took a 30 minutes walk in my new neighborhoo...   \n",
              "\n",
              "                                            Spr 9-10  Unnamed: 13  \\\n",
              "0  Set aside and spent some time at night after s...          NaN   \n",
              "1  I painted my nails! This is something I really...          NaN   \n",
              "2  This weekend, I went shopping with my friend a...          NaN   \n",
              "3         I went out and had lunch with my brother.           NaN   \n",
              "4  It was a nice day today and my friend and I to...          NaN   \n",
              "\n",
              "                                              CPD_Q1  \\\n",
              "0  The class time devoted to health and wellness ...   \n",
              "1  The class time devoted to health and wellness ...   \n",
              "2  The class time has reminded me on the importan...   \n",
              "3  The class time that was devoted to health and ...   \n",
              "4  I have learnt to listen to people without inte...   \n",
              "\n",
              "                                              CPD_Q2  \\\n",
              "0  During my gap years I gained a lot of insight ...   \n",
              "1  The way I decided which self-care to choose wa...   \n",
              "2  To decide on what to do it would mostly depend...   \n",
              "3  For me, it depends on the weather à if it was ...   \n",
              "4  This is because I wanted to connect with mysel...   \n",
              "\n",
              "                                              CPD_Q3  \n",
              "0  I believe self-care to be really important in ...  \n",
              "1  The time spent on my choice of self-care allow...  \n",
              "2  The time spent on my choice of self care affec...  \n",
              "3  It made me more relaxed and less stressed abou...  \n",
              "4  This has been a lifeline because I always felt...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"data/choiceboard_data.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "avhWbStY-E7b",
        "outputId": "e2348137-8a53-41e1-b5d2-f06e1850d475"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CPD_Q1</th>\n",
              "      <th>CPD_Q3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The class time devoted to health and wellness ...</td>\n",
              "      <td>I believe self-care to be really important in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The class time devoted to health and wellness ...</td>\n",
              "      <td>The time spent on my choice of self-care allow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The class time has reminded me on the importan...</td>\n",
              "      <td>The time spent on my choice of self care affec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The class time that was devoted to health and ...</td>\n",
              "      <td>It made me more relaxed and less stressed abou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I have learnt to listen to people without inte...</td>\n",
              "      <td>This has been a lifeline because I always felt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              CPD_Q1  \\\n",
              "0  The class time devoted to health and wellness ...   \n",
              "1  The class time devoted to health and wellness ...   \n",
              "2  The class time has reminded me on the importan...   \n",
              "3  The class time that was devoted to health and ...   \n",
              "4  I have learnt to listen to people without inte...   \n",
              "\n",
              "                                              CPD_Q3  \n",
              "0  I believe self-care to be really important in ...  \n",
              "1  The time spent on my choice of self-care allow...  \n",
              "2  The time spent on my choice of self care affec...  \n",
              "3  It made me more relaxed and less stressed abou...  \n",
              "4  This has been a lifeline because I always felt...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cpd = df[[\"CPD_Q1\", \"CPD_Q3\"]]\n",
        "df_cpd.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehfqzrfR-G4s",
        "outputId": "e09e6252-bb70-4007-cd05-0ac873d2f211"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      The class time devoted to health and wellness ...\n",
              "1      The class time devoted to health and wellness ...\n",
              "2      The class time has reminded me on the importan...\n",
              "3      The class time that was devoted to health and ...\n",
              "4      I have learnt to listen to people without inte...\n",
              "                             ...                        \n",
              "103    It’s been a wonderful change of pace to have a...\n",
              "104    The mentor team discussions with my team and p...\n",
              "105    The class time devoted to health, wellness, an...\n",
              "106    I personally think it was a nice break, but I ...\n",
              "107    I actively disliked most of the content relate...\n",
              "Name: CPD_Q1, Length: 105, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_1 = df_cpd[\"CPD_Q1\"].dropna()\n",
        "corpus_1 = corpus_1.astype(str)\n",
        "corpus_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MSQ7hLZ0-JxI"
      },
      "outputs": [],
      "source": [
        "#adding clearly neutral stopwords that are specific to this program or activity\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "stopwords.append('pharmacy')\n",
        "stopwords.append('pharmacist')\n",
        "stopwords.append('pharmacists')\n",
        "stopwords.append('health')\n",
        "stopwords.append('healthcare')\n",
        "stopwords.append('practitioner')\n",
        "stopwords.append('mental')\n",
        "stopwords.append('wellness')\n",
        "stopwords.append('self-care')\n",
        "stopwords.append('mentor')\n",
        "stopwords.append('WIP')\n",
        "stopwords.append('class')\n",
        "stopwords.append('school')\n",
        "stopwords.append('peers')\n",
        "stopwords.append('classmates')\n",
        "stopwords.append('quarter')\n",
        "stopwords.append('spring')\n",
        "stopwords.append('winter')\n",
        "stopwords.append('fall')\n",
        "stopwords.append('time')\n",
        "\n",
        "stopwords = list(stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgsLtymhpBzW"
      },
      "source": [
        "## SAMPLING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WbHYnrlc-MdQ",
        "outputId": "e69dd048-bdc5-4ad9-af11-9a8691fee186"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CPD_Q1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the class time devoted to health and wellness ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the class time devoted to health and wellness ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the class time has reminded me on the importan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the class time that was devoted to health and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i have learnt to listen to people without inte...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              CPD_Q1\n",
              "0  the class time devoted to health and wellness ...\n",
              "1  the class time devoted to health and wellness ...\n",
              "2  the class time has reminded me on the importan...\n",
              "3  the class time that was devoted to health and ...\n",
              "4  i have learnt to listen to people without inte..."
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#using sample of words from full corpus\n",
        "sample = pd.DataFrame(corpus_1).reset_index()[['CPD_Q1']]\n",
        "sample['CPD_Q1'] = sample['CPD_Q1'].map(lambda x: x.lower())\n",
        "sample.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kplx-h3pIMA"
      },
      "source": [
        "## DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3GeOnW4-geQ",
        "outputId": "262a03ca-a3ba-44cf-c244-b02a2ecdc9b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'class', 'time', 'devoted', 'to', 'health', 'and', 'wellness', 'and', 'self', 'care', 'has', 'had', 'positive', 'effect', 'on', 'me', 'while', 'am', 'fairly', 'good', 'at', 'finding', 'pockets', 'of', 'time', 'for', 'self', 'care', 'myself']\n"
          ]
        }
      ],
      "source": [
        "def sent_to_words(sentences):\n",
        "  \"gensim simple preprocess removes punctuation, lowercases, and tokenizes\"\n",
        "  for sentence in sentences:\n",
        "    yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data = sample.CPD_Q1.values.tolist()\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words[:1][0][:30]) #first 30 words of the first comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wBRitfTh_JHS"
      },
      "outputs": [],
      "source": [
        "#bigrams\n",
        "#phrases that go together, like \"new york\" (bigram)\n",
        "\n",
        "#build the models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases\n",
        "\n",
        "#fast way to get bigrams and trigrams\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ONlhcujbAKuk"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in doc if word not in stopwords] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']): #only looking at these POS!\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent))\n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzEEapELAXtE",
        "outputId": "ff41cc84-72e2-4343-ae18-81cf0c4eb2b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['class', 'time', 'devote', 'health', 'wellness', 'self', 'care', 'have', 'positive', 'effect', 'fairly', 'good', 'find', 'pocket', 'time', 'self', 'care', 'class', 'session', 'such', 'mentor', 'team', 'discussion', 'provide', 'space', 'engage', 'normally', 'think', 'do', 'such']\n"
          ]
        }
      ],
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words) #data_words_nostops\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "# data_words_bigrams == data_words => true\n",
        "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1][0][:30]) #1st 30 words of 1st comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uf2_pIwEu3l",
        "outputId": "5b6f07f7-1432-493d-a54f-cc6990d74861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 2), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2)]\n"
          ]
        }
      ],
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJrZlDLWQvW6"
      },
      "source": [
        "## BASELINE LDA MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Validation_Set</th>\n",
              "      <th>Topics</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>Beta</th>\n",
              "      <th>Coherence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>2</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.472374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>75% Corpus</td>\n",
              "      <td>3</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.567585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>75% Corpus</td>\n",
              "      <td>4</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.552350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>75% Corpus</td>\n",
              "      <td>5</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.600130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>75% Corpus</td>\n",
              "      <td>6</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.669763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>75% Corpus</td>\n",
              "      <td>7</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.619368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>8</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.683775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>9</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.677629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>75% Corpus</td>\n",
              "      <td>10</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.644418</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Validation_Set  Topics       Alpha                Beta  Coherence\n",
              "277    100% Corpus       2        0.31                0.61   0.472374\n",
              "58      75% Corpus       3  asymmetric  0.9099999999999999   0.567585\n",
              "68      75% Corpus       4        0.31  0.9099999999999999   0.552350\n",
              "103     75% Corpus       5        0.61  0.9099999999999999   0.600130\n",
              "133     75% Corpus       6        0.61  0.9099999999999999   0.669763\n",
              "177     75% Corpus       7  asymmetric                0.61   0.619368\n",
              "463    100% Corpus       8        0.61  0.9099999999999999   0.683775\n",
              "493    100% Corpus       9        0.61  0.9099999999999999   0.677629\n",
              "268     75% Corpus      10  asymmetric  0.9099999999999999   0.644418"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = pd.read_csv(\"lda_tuning_results.csv\")\n",
        "results.loc[results.groupby('Topics')['Coherence'].idxmax()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "twkGok8TQn5z"
      },
      "outputs": [],
      "source": [
        "# Build baseline LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=2, #starting number\n",
        "                                       random_state=100,\n",
        "                                       chunksize=100, #of docs processed\n",
        "                                       passes=10, #epochs\n",
        "                                       alpha=0.31,\n",
        "                                       eta=0.61,\n",
        "                                       per_word_topics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ESc7KctS0c8",
        "outputId": "7bc8cd6f-885f-4135-f301-6fb67ffe8298"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.034*\"time\" + 0.024*\"class\" + 0.019*\"take\" + 0.019*\"health\" + 0.016*\"have\" + 0.016*\"care\" + 0.015*\"wellness\" + 0.010*\"other\" + 0.010*\"feel\" + 0.010*\"think\"'),\n",
              " (1,\n",
              "  '0.036*\"time\" + 0.018*\"health\" + 0.017*\"class\" + 0.016*\"care\" + 0.016*\"do\" + 0.014*\"self\" + 0.014*\"help\" + 0.014*\"have\" + 0.013*\"wellness\" + 0.012*\"mentor\"')]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda_model.print_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnYQolVDv3XF"
      },
      "source": [
        "## COHERENCE MODELING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyF2evm1lsZn",
        "outputId": "0b0555ef-b5ca-4c74-c188-23fe06d4dd09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coherence Score:  0.38777825685462775\n"
          ]
        }
      ],
      "source": [
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('Coherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "xQI2MASqmVnT",
        "outputId": "d81256db-7971-400e-e2ae-817a3538a42a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topics</th>\n",
              "      <th>Coherence Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.408545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0.390361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0.388981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0.413907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0.353577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7</td>\n",
              "      <td>0.436294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8</td>\n",
              "      <td>0.380043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9</td>\n",
              "      <td>0.425088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>0.420265</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topics  Coherence Score\n",
              "0       2         0.408545\n",
              "1       3         0.390361\n",
              "2       4         0.388981\n",
              "3       5         0.413907\n",
              "4       6         0.353577\n",
              "5       7         0.436294\n",
              "6       8         0.380043\n",
              "7       9         0.425088\n",
              "8      10         0.420265"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tracker = pd.DataFrame(columns=['Topics', 'Coherence Score'])\n",
        "\n",
        "for i in np.arange(2, 11):\n",
        "  test_lda = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=i,\n",
        "                                       random_state=42,\n",
        "                                       chunksize=100,\n",
        "                                       passes=10,\n",
        "                                       alpha=0.31,\n",
        "                                       eta=0.61)\n",
        "  test_coher = CoherenceModel(model=test_lda, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "  test_coher_lda = test_coher.get_coherence()\n",
        "  new_row = {\"Topics\": i, \"Coherence Score\": test_coher_lda}\n",
        "  tracker.loc[len(tracker.index)] = new_row\n",
        "\n",
        "tracker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Oc1KU4JsqNM",
        "outputId": "8ef0f1f2-4a05-4245-87b3-deda2c021ba0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.029*\"time\" + 0.019*\"class\" + 0.016*\"care\" + 0.015*\"health\" + 0.014*\"wellness\" + 0.013*\"self\" + 0.011*\"find\" + 0.010*\"take\" + 0.010*\"have\" + 0.009*\"quarter\"'),\n",
              " (1,\n",
              "  '0.039*\"time\" + 0.022*\"class\" + 0.021*\"health\" + 0.018*\"have\" + 0.017*\"care\" + 0.015*\"wellness\" + 0.015*\"help\" + 0.015*\"think\" + 0.015*\"do\" + 0.013*\"feel\"')]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "two_topics = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=2,\n",
        "                                       random_state=42,\n",
        "                                       passes=10)\n",
        "two_topics.print_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWpIL3ZVtlx5"
      },
      "source": [
        "These two topics have very overlapping words, so it's not ideal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDobLvWitiNN",
        "outputId": "579e0758-464f-41a2-be1e-430e02a7b871"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.020*\"time\" + 0.019*\"self\" + 0.015*\"compassionate\" + 0.015*\"team\" + 0.013*\"care\" + 0.013*\"wellness\" + 0.013*\"patient\" + 0.011*\"class\" + 0.011*\"health\" + 0.011*\"find\"'),\n",
              " (1,\n",
              "  '0.031*\"time\" + 0.022*\"health\" + 0.022*\"have\" + 0.015*\"school\" + 0.015*\"wellness\" + 0.015*\"mentor\" + 0.015*\"class\" + 0.015*\"care\" + 0.014*\"team\" + 0.013*\"other\"'),\n",
              " (2,\n",
              "  '0.018*\"allow\" + 0.016*\"have\" + 0.016*\"time\" + 0.015*\"class\" + 0.013*\"other\" + 0.011*\"discussion\" + 0.011*\"play\" + 0.011*\"do\" + 0.009*\"team\" + 0.009*\"health\"'),\n",
              " (3,\n",
              "  '0.058*\"time\" + 0.034*\"class\" + 0.028*\"care\" + 0.023*\"health\" + 0.020*\"do\" + 0.019*\"take\" + 0.019*\"have\" + 0.017*\"wellness\" + 0.017*\"self\" + 0.013*\"help\"'),\n",
              " (4,\n",
              "  '0.038*\"time\" + 0.024*\"class\" + 0.021*\"help\" + 0.020*\"think\" + 0.017*\"health\" + 0.016*\"take\" + 0.016*\"care\" + 0.014*\"wellness\" + 0.014*\"break\" + 0.013*\"really\"')]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "five_topics = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=5,\n",
        "                                       random_state=42,\n",
        "                                       passes=10)\n",
        "five_topics.print_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbzWtIZnt1wN"
      },
      "source": [
        "Topic 0 - emotional: mentions compassion and patient => human-centered\n",
        "\n",
        "Topic 1 - mentions having a mentor and a team environment\n",
        "\n",
        "Topic 2 - allows for discussions and time to play\n",
        "\n",
        "Topic 3 - helps a lot to have classtime for health and self-care\n",
        "\n",
        "Topic 4 - prompts students to think more seriously about health/wellness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpQIVEsflsSy"
      },
      "source": [
        "There are a lot of overlapping words in these topics, making these interpretations HIGHLY subjective => want to try looking at other packages that are more tuned for short text tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmTckXf9lmYT"
      },
      "source": [
        "Notes (1/25):\n",
        "- Try STTM? https://github.com/rwalk/gsdmm\n",
        "- Visualize using PyLDADavis\n",
        "- Brainstorm how I will validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_owMF0fDl5pg"
      },
      "source": [
        "## tweetopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KhZkSHtql5Gb"
      },
      "outputs": [],
      "source": [
        "#%pip install tweetopic\n",
        "#%pip install git+https://github.com/rwalk/gsdmm.git\n",
        "#from gsdmm import MovieGroupProcess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_yEjHjx2l7x5"
      },
      "outputs": [],
      "source": [
        "# https://github.com/centre-for-humanities-computing/tweetopic\n",
        "import tweetopic\n",
        "from tweetopic import DMM\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9JR8wYb7tcD-"
      },
      "outputs": [],
      "source": [
        "# Creating a vectorizer for extracting document-term matrix from the\n",
        "# text corpus.\n",
        "vectorizer = CountVectorizer(min_df=2, max_df=0.95, stop_words=stopwords) #ignore terms that appear in more than 2 docs, ignore terms that occur in more than 95% of docs\n",
        "# Creating a Dirichlet Multinomial Mixture Model with 5 components\n",
        "dmm = DMM(n_components=5, n_iterations=5, alpha=0.1, beta=0.1)\n",
        "\n",
        "# Creating topic pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"vectorizer\", vectorizer),\n",
        "    (\"dmm\", dmm),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "_NyfBYqZvvex",
        "outputId": "fe87bc98-a61a-4a72-9be1-7d806fb744a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jergx\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['care', 'self', 'wip'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing components.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Sampling: 100%|██████████| 5/5 [00:01<00:00,  3.18it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
              "                 CountVectorizer(max_df=0.95, min_df=2,\n",
              "                                 stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;,\n",
              "                                             &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
              "                                             &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
              "                                             &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;,\n",
              "                                             &#x27;yourself&#x27;, &#x27;yourselves&#x27;, &#x27;he&#x27;,\n",
              "                                             &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
              "                                             &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;,\n",
              "                                             &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;, &#x27;itself&#x27;, ...])),\n",
              "                (&#x27;dmm&#x27;, DMM(n_components=5, n_iterations=5))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
              "                 CountVectorizer(max_df=0.95, min_df=2,\n",
              "                                 stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;,\n",
              "                                             &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
              "                                             &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
              "                                             &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;,\n",
              "                                             &#x27;yourself&#x27;, &#x27;yourselves&#x27;, &#x27;he&#x27;,\n",
              "                                             &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
              "                                             &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;,\n",
              "                                             &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;, &#x27;itself&#x27;, ...])),\n",
              "                (&#x27;dmm&#x27;, DMM(n_components=5, n_iterations=5))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_df=0.95, min_df=2,\n",
              "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
              "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
              "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
              "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
              "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
              "                            &#x27;itself&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DMM</label><div class=\"sk-toggleable__content\"><pre>DMM(n_components=5, n_iterations=5)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 CountVectorizer(max_df=0.95, min_df=2,\n",
              "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
              "                                             'our', 'ours', 'ourselves', 'you',\n",
              "                                             \"you're\", \"you've\", \"you'll\",\n",
              "                                             \"you'd\", 'your', 'yours',\n",
              "                                             'yourself', 'yourselves', 'he',\n",
              "                                             'him', 'his', 'himself', 'she',\n",
              "                                             \"she's\", 'her', 'hers', 'herself',\n",
              "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
              "                ('dmm', DMM(n_components=5, n_iterations=5))])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.fit(list(corpus_1)) #raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "GsxYxEDJwUXV",
        "outputId": "0f132cf9-507b-4a65-e320-6be0aa04075f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"650\"\n",
              "            src=\"http://127.0.0.1:8050/\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x20df9cfafb0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import topicwizard\n",
        "\n",
        "topicwizard.visualize(pipeline=pipeline, corpus=corpus_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
